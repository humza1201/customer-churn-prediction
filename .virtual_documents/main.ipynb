import pandas as pd


data = pd.read_csv('telco-customer-churn.csv')


df = pd.DataFrame(data)


df.head()


# ans 1) no of rows = 7043 and no of columns = 21


df.shape


df.info()


# float64(1), int64(2), object(18) -> numerical , categorical features 


df['TotalCharges']


# Convert column to float and store back in original DataFrame
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')


df['TotalCharges'].dtype


df.info()


df[df['TotalCharges'].isna()]


df.loc[df['tenure'] == 0, 'TotalCharges'] = 0


ten_bins = [0,12, 24, 48, 72]


df['tenure_bin'] = pd.cut(df['tenure'], bins=ten_bins, labels=["0–12", "12–24", "24–48", "48–72"], right=False)


df


df.info()


df[df['Contract'] == "Two year"]


# churn_rate_by_monthlycharges = df.groupby('MonthlyCharges', observed=True)['Churn'].apply(lambda x: (x == "Yes").mean()*100)


bins = [0, 35, 70, 120]
df['monthly_bins'] = pd.cut(df['MonthlyCharges'] , bins = bins, labels=["0–35", "35–70", "70–120"], right=False)


from sklearn.model_selection import StratifiedShuffleSplit


split = StratifiedShuffleSplit(n_splits = 1, test_size=0.3 , random_state=42)


for train_ind , test_ind in split.split(df , df['monthly_bins']):
    strata_train_set = df.iloc[train_ind]
    strata_test_set = df.iloc[test_ind]
    


strata_train_set


train_set = strata_train_set.copy()


train_set = train_set.drop([
     'tenure_bin',
     'monthly_bins'
] ,axis=1)


train_set_features = train_set.iloc[:,:-1]


train_set_labels = train_set.iloc[:,-1]


train_set_labels


train_set_features['SeniorCitizen'] = train_set_features['SeniorCitizen'].astype('object')


num_attr = train_set_features.select_dtypes(include=['int64','float64']).columns.tolist()


num_attr


# cat_attr = [col for col in train_set_features if col not in ['customerID', 'Churn']]
cat_attr = [col for col in train_set_features.columns 
            if col not in num_attr + ['customerID']]


cat_attr


from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer


num_pipline = Pipeline(
    [
        ("stan_scalar",StandardScaler())
    ]
)


cat_pipeline = Pipeline([
    ("encoder" , OneHotEncoder(handle_unknown="ignore"))
])


full_pipeline = ColumnTransformer(
    [
        ("num" , num_pipline, num_attr),
        ("cat", cat_pipeline, cat_attr)
    ]
)


complete_preprocessed_data = full_pipeline.fit_transform(train_set_features)


complete_preprocessed_data


complete_preprocessed_data.shape


# column_names


column_names = full_pipeline.get_feature_names_out()
complete_preprocessed_data_df = pd.DataFrame(complete_preprocessed_data, columns= column_names , index = train_set_features.index)


from sklearn.linear_model import LogisticRegression


lrg = LogisticRegression(class_weight='balanced' ,random_state=42)


lrg.fit(complete_preprocessed_data, train_set_labels)


lrg_preds = lrg.predict(complete_preprocessed_data)


lrg_preds


test_set = strata_test_set.copy()


test_set = test_set.drop([
     'tenure_bin',
     'monthly_bins'
] ,axis=1)


test_set_features = test_set.iloc[:,:-1]
test_set_labels = test_set.iloc[:,-1]


test_set_features['SeniorCitizen'] = test_set_features['SeniorCitizen'].astype('object')


test_num_attr = test_set_features.select_dtypes(include=['int64','float64']).columns.tolist()
test_cat_attr = [col for col in test_set_features if col not in ['customerID', 'Churn']]


complete_preprocessed_test_data = full_pipeline.transform(test_set_features)
column_names_test = full_pipeline.get_feature_names_out()
complete_preprocessed_test_data_df = pd.DataFrame(complete_preprocessed_test_data, columns= column_names_test , index = test_set_features.index)


lrg_pred = lrg.predict(complete_preprocessed_test_data)


lrg_pred


count = 0
for i in range(len(test_set_labels)):
    if test_set_labels.iloc[i] == lrg_pred[i]:
        count = count + 1

accuracy = (count / len(test_set_labels)) * 100
print(f"Accuracy: {accuracy:.2f}%")

# for i in range(len(train_set_labels)):
#     print(train_set_labels.iloc[i]) # for debugginh



from sklearn.metrics import recall_score, f1_score, roc_auc_score, classification_report, roc_curve


recall = recall_score(test_set_labels, lrg_pred, pos_label="Yes")

f1 = f1_score(test_set_labels, lrg_pred, pos_label="Yes")

lrg_pred_proba = lrg.predict_proba(complete_preprocessed_test_data)[:, 1]  # probabilities for ROC-AUC
roc_auc = roc_auc_score(test_set_labels.map({"No":0, "Yes":1}), lrg_pred_proba)

print(f"Recall: {recall:.2f}")
print(f"F1-score: {f1:.2f}")
print(f"ROC-AUC: {roc_auc:.2f}")




